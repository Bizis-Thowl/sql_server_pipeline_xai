{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi.confidence import TrustScore\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_index = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData, text\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import registry, Session\n",
    "\n",
    "from util import get_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "Base = automap_base(metadata=metadata)\n",
    "Base.prepare(autoload_with=engine)\n",
    "mapper_registry = registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = [\"datapoint_feature_value\", \"datapoint_class_label\", \"datapoint_filter\", \"datapoint\", \"datapoint_mappings\", \"feature\", \"model\"]\n",
    "dfs = []\n",
    "\n",
    "for table in table_names:\n",
    "    with engine.begin() as conn:\n",
    "        query = text(\"\"\"SELECT * FROM \"\"\" + table)\n",
    "        dfs.append(pd.read_sql_query(query, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_df = dfs[3]\n",
    "datapoint_mappings_df = dfs[4]\n",
    "datapoint_feature_value_df = dfs[0]\n",
    "feature_df = dfs[5]\n",
    "datapoint_class_label_df = dfs[1]\n",
    "datapoint_filter_df = dfs[2]\n",
    "model_df = dfs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datapoint DataFrame with datapoint_mappings to get the grouping (train/test).\n",
    "datapoints_merged = pd.merge(datapoint_df, datapoint_mappings_df, left_on='datapoint_mappings_id', right_on='id', suffixes=('_datapoint', '_mappings'))\n",
    "\n",
    "# Pivot the datapoint_feature_value table.\n",
    "pivot_feature_values = datapoint_feature_value_df.pivot(index='datapoint_id', columns='feature_id', values='value').reset_index()\n",
    "\n",
    "# Rename pivot_feature_values columns using the feature names for readability.\n",
    "pivot_feature_values.columns = ['datapoint_id'] + feature_df.set_index('id').loc[pivot_feature_values.columns[1:]]['name'].tolist()\n",
    "\n",
    "# Merge the class label and filter values with the datapoints.\n",
    "final_df = pd.merge(pivot_feature_values, datapoint_class_label_df[['datapoint_id', 'label_categorical_id']], on='datapoint_id', how='left').rename(columns={'label_categorical_id': 'class_label'})\n",
    "final_df = pd.merge(final_df, datapoint_filter_df[['datapoint_id', 'value']], on='datapoint_id', how='left', suffixes=('', '_filter')).rename(columns={'value': 'filter_value'})\n",
    "\n",
    "# Merge with the datetime and grouping information from datapoints_merged.\n",
    "final_df = pd.merge(final_df, datapoints_merged[['id_datapoint', 'datetime', 'grouping']], left_on='datapoint_id', right_on='id_datapoint', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'label_categorical_id': 'class_label'}); final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select and reorder columns as needed (optional).\n",
    "final_columns = ['datapoint_id', 'datetime', 'grouping', 'filter_value', 'class_label'] + feature_df['name'].tolist()\n",
    "final_df = final_df[final_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"path_to_model\"][model_id_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(model_df[\"path_to_model\"][model_id_index], 'rb'))\n",
    "model_features_in = list(model.feature_names_in_); model_features_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_out = model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transform(row):\n",
    "    print(row[\"class_label\"])\n",
    "    if row[\"class_label\"] == 1: return 0\n",
    "    elif row[\"class_label\"] == 2: return 1\n",
    "    elif row[\"class_label\"] == 3: return 2\n",
    "    elif row[\"class_label\"] == 4: return 3\n",
    "    elif row[\"class_label\"] == 5: return 4\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_df[final_df['grouping'] == \"train\"][model_features_in]\n",
    "X_test = final_df[final_df['grouping'] == \"test\"][model_features_in]\n",
    "y_train = final_df[final_df['grouping'] == \"train\"][\"class_label\"]\n",
    "y_train_trans = final_df[final_df['grouping'] == \"train\"].apply(label_transform, axis=1)\n",
    "y_test = final_df[final_df['grouping'] == \"test\"][\"class_label\"]\n",
    "y_test_trans = final_df[final_df['grouping'] == \"test\"].apply(label_transform, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train.to_numpy()); y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame({'pred': y_pred, 'label': y_train}, columns=['pred', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def confusion_matrix(df: pd.DataFrame, col1: str, col2: str):\n",
    "    \"\"\"\n",
    "    Given a dataframe with at least\n",
    "    two categorical columns, create a \n",
    "    confusion matrix of the count of the columns\n",
    "    cross-counts\n",
    "    \n",
    "    use like:\n",
    "    \n",
    "    >>> confusion_matrix(test_df, 'actual_label', 'predicted_label')\n",
    "    \"\"\"\n",
    "\n",
    "    print(balanced_accuracy_score(df[col1], df[col2]))\n",
    "    \n",
    "    return (\n",
    "            df\n",
    "            .groupby([col1, col2])\n",
    "            .size()\n",
    "            .unstack(fill_value=0)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(my_df, \"pred\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_object = shap.Explanation(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_object.values[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", class_names=[0,1,2,3,4], feature_names = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: model.predict_proba(x)\n",
    "feature_names = X_train.columns.to_list()\n",
    "explainer = AnchorTabular(predict_fn, feature_names)\n",
    "multiplier = 25\n",
    "entries = int((100 / multiplier) - 1)\n",
    "explainer.fit(X_train.to_numpy(), disc_perc=(tuple([(x+1) * multiplier for x in range(entries)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = X_test.to_numpy()\n",
    "test_length = X_test_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(sec):\n",
    "  mins = sec // 60\n",
    "  sec = sec % 60\n",
    "  hours = mins // 60\n",
    "  mins = mins % 60\n",
    "  return \"Time Lapsed = {0}:{1}:{2}\".format(int(hours),int(mins),sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = X_test.to_numpy()\n",
    "X_test_np.shape\n",
    "start_time = time.time()\n",
    "\n",
    "anchors = []\n",
    "for i, dp in enumerate(X_test_np):\n",
    "    explanation = explainer.explain(dp, threshold=0.95)\n",
    "    anchors.append(explanation)\n",
    "    current_time = time.time()\n",
    "    time_lapsed = current_time - start_time\n",
    "    print(\"{} von {} Schritten abgeschlossen. Zeit: {}. Precision: {}\".format(i, test_length, time_convert(time_lapsed), explanation[\"data\"][\"precision\"]), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors[1][\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trustscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.classes_-1; classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_norm = y_train.to_numpy()-1\n",
    "y_test_norm = y_test.to_numpy() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TrustScore()\n",
    "ts.fit(X_train.to_numpy(), y_train_norm, classes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ts.score(X_test, y_test_norm, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(datapoint_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sum  = 0\n",
    "conf_sum = 0\n",
    "for i, score in enumerate(scores[1]):\n",
    "    abs_dist = abs(y_test_trans.iloc[i] - (score))\n",
    "    dist_sum = dist_sum + abs_dist\n",
    "    conf_sum = conf_sum + scores[0][i]\n",
    "\n",
    "print(dist_sum / len(scores[1]))\n",
    "print(conf_sum / len(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare model wrapper to output numerical values instead of categorical values (i.e. 0 instead of \"low\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CategoricalToNumericalClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_model, class_mapping):\n",
    "        self.base_model = base_model\n",
    "        self.class_mapping = class_mapping\n",
    "        self.classes_ = list(class_mapping.values())\n",
    "        # Reverse mapping for decoding\n",
    "        self.reverse_mapping = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # This model is already trained, so we don't do anything here\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict using the base model\n",
    "        predictions = self.base_model.predict(X)\n",
    "        # Map categorical predictions to numerical\n",
    "        return [self.class_mapping.get(pred, -1) for pred in predictions]  # Default to -1 for unknown classes\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Optional: Implement this if you need probability estimates\n",
    "        # and your base model supports it\n",
    "        if hasattr(self.base_model, 'predict_proba'):\n",
    "            return self.base_model.predict_proba(X)\n",
    "        else:\n",
    "            raise NotImplementedError(\"This model does not support predict_proba.\")\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        # Convert numerical predictions back to categorical\n",
    "        return [self.reverse_mapping[pred] for pred in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {'low': 0, 'low-med': 1, 'medium': 2, 'med-high': 3, 'high': 4}\n",
    "model_wrapper = CategoricalToNumericalClassifier(base_model=model, class_mapping=class_mapping)\n",
    "\n",
    "# this does nothing as the model is already trained! It is just done to sign that the model is trained\n",
    "model_wrapper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, feature in enumerate(X_test.columns):\n",
    "    pdp = partial_dependence(model_wrapper, X_test, [index], kind=\"average\")\n",
    "    for cl_index, cl in enumerate(model_wrapper.classes_):\n",
    "        print(\n",
    "            {\n",
    "                \"feature\": feature,\n",
    "                \"class\": int(cl),\n",
    "                \"average\": pdp[\"average\"][cl_index].tolist()\n",
    "            }\n",
    "        )\n",
    "        print(\n",
    "            {\n",
    "                \"feature\": feature,\n",
    "                \"class\": int(cl),\n",
    "                \"values\": pdp[\"values\"][0].tolist()\n",
    "            }\n",
    "        )\n",
    "        # for elem_ind, elem in enumerate(pdp[\"individual\"][cl_index]):\n",
    "        #     print(\n",
    "        #         {\n",
    "        #             \"feature\": feature,\n",
    "        #             \"class\": int(cl),\n",
    "        #             \"index\": elem_ind,\n",
    "        #             \"individual\": elem.tolist()\n",
    "        #         }\n",
    "        #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(model_wrapper, X_train, [X_train.columns[4]], target=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import create_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = dict()\n",
    "context[\"Base\"] = Base\n",
    "context[\"session\"] = Session(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_df[datapoint_df[\"datapoint_mappings_id\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO setup correct model reference\n",
    "feature_ids = list(feature_df[\"id\"])\n",
    "datapoint_ids = list(datapoint_df[datapoint_df[\"datapoint_mappings_id\"] == 2][\"id\"])\n",
    "\n",
    "for i, feature in enumerate(model_features_in):\n",
    "    for j, datapoint_id in enumerate(datapoint_ids):\n",
    "        for k, class_id in enumerate(classes_out):\n",
    "            create_object(context, \"shap\", with_commit=False,\n",
    "                        model_id = int(model_df[\"id\"][model_id_index]),\n",
    "                        feature_id = int(feature_df[feature_df[\"name\"]==feature].id),\n",
    "                        datapoint_id = int(datapoint_id),\n",
    "                        label_id = int(k+1),\n",
    "                        # TODO: add SHAP values based on shap value data structure\n",
    "                        value = float(shap_values[j][i][k])\n",
    "                      )\n",
    "        if j % 5000 == 0 and j != 0:\n",
    "            print(\"yo\")\n",
    "            context[\"session\"].commit()\n",
    "\n",
    "context[\"session\"].commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, datapoint_id in enumerate(datapoint_ids):\n",
    "    create_object(context, \"anchors\", with_commit=False,\n",
    "                    id = i,\n",
    "                    model_id = model.id,\n",
    "                    datapoint_id = datapoint_id,\n",
    "                    # TODO: add Anchor performance values based on anchor data structure\n",
    "                    precision = None,\n",
    "                    coverage = None\n",
    "                )\n",
    "    for feature_id in feature_ids:\n",
    "        create_object(context, \"anchor_rules\", with_commit=False,\n",
    "                        anchor_id = i,\n",
    "                        feature_id = feature_id,\n",
    "                        # TODO: add boundary values based on anchor data structure\n",
    "                        lower_bound = None,\n",
    "                        upper_bound = None\n",
    "                    )\n",
    "    if (i % 5000 == 0 and i != 0):\n",
    "        context[\"session\"].commit()\n",
    "# Final commit in case something was not commited yet\n",
    "context[\"session\"].commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_ids = list(datapoint_df[datapoint_df[\"datapoint_mappings_id\"] == 2][\"id\"])\n",
    "for i, datapoint_id in enumerate(datapoint_ids):\n",
    "    create_object(context, \"trustscores\", with_commit=False,\n",
    "                    model_id = int(model_df[\"id\"][model_id_index]),\n",
    "                    datapoint_id = int(datapoint_id),\n",
    "                    neighbor = int(scores[1][i]+1),\n",
    "                    score = float(scores[0][i])\n",
    "    )\n",
    "    if (i % 5000 == 0 and i != 0):\n",
    "        print(\"yo\")\n",
    "        context[\"session\"].commit()\n",
    "# Final commit in case something was not commited yet\n",
    "context[\"session\"].commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, feature_id in enumerate(feature_ids):\n",
    "    for j, class_id in enumerate(classes):\n",
    "        # Calculate unique, up-counting id based on i and j.\n",
    "        unique_id = ((i+j) * (i+j+1) / 2) + j\n",
    "        create_object(context, \"partial_dependence\", with_commit=False,\n",
    "                        id = unique_id,\n",
    "                        model_id = model.id,\n",
    "                        feature_id = feature_id,\n",
    "                        label_id = class_id\n",
    "                      )\n",
    "        create_object(context, \"partial_dependence_average\", with_commit=False,\n",
    "                    partial_dependence_id = unique_id,\n",
    "                    # TODO: add PDP values based on PDP data structure\n",
    "                    feature_value = None,\n",
    "                    pd_value = None,\n",
    "                    index = None\n",
    "                )\n",
    "        \n",
    "context[\"session\"].commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
