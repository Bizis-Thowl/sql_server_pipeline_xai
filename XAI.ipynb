{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from alibi.explainers import AnchorTabular\n",
    "from alibi.confidence import TrustScore\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData, text\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import registry, Session\n",
    "\n",
    "from util import get_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_engine()\n",
    "metadata = MetaData()\n",
    "metadata.reflect(bind=engine)\n",
    "Base = automap_base(metadata=metadata)\n",
    "Base.prepare(autoload_with=engine)\n",
    "mapper_registry = registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = [\"datapoint_feature_value\", \"datapoint_class_label\", \"datapoint_filter\", \"datapoint\", \"datapoint_mappings\", \"feature\", \"model\"]\n",
    "dfs = []\n",
    "\n",
    "for table in table_names:\n",
    "    with engine.begin() as conn:\n",
    "        query = text(\"\"\"SELECT * FROM \"\"\" + table)\n",
    "        dfs.append(pd.read_sql_query(query, conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoint_df = dfs[3]\n",
    "datapoint_mappings_df = dfs[4]\n",
    "datapoint_feature_value_df = dfs[0]\n",
    "feature_df = dfs[5]\n",
    "datapoint_class_label_df = dfs[1]\n",
    "datapoint_filter_df = dfs[2]\n",
    "model_df = dfs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the datapoint DataFrame with datapoint_mappings to get the grouping (train/test).\n",
    "datapoints_merged = pd.merge(datapoint_df, datapoint_mappings_df, left_on='datapoint_mappings_id', right_on='id', suffixes=('_datapoint', '_mappings'))\n",
    "\n",
    "# Pivot the datapoint_feature_value table.\n",
    "pivot_feature_values = datapoint_feature_value_df.pivot(index='datapoint_id', columns='feature_id', values='value').reset_index()\n",
    "\n",
    "# Rename pivot_feature_values columns using the feature names for readability.\n",
    "pivot_feature_values.columns = ['datapoint_id'] + feature_df.set_index('id').loc[pivot_feature_values.columns[1:]]['name'].tolist()\n",
    "\n",
    "# Merge the class label and filter values with the datapoints.\n",
    "final_df = pd.merge(pivot_feature_values, datapoint_class_label_df[['datapoint_id', 'label_categorical_id']], on='datapoint_id', how='left').rename(columns={'label_categorical_id': 'class_label'})\n",
    "final_df = pd.merge(final_df, datapoint_filter_df[['datapoint_id', 'value']], on='datapoint_id', how='left', suffixes=('', '_filter')).rename(columns={'value': 'filter_value'})\n",
    "\n",
    "# Merge with the datetime and grouping information from datapoints_merged.\n",
    "final_df = pd.merge(final_df, datapoints_merged[['id_datapoint', 'datetime', 'grouping']], left_on='datapoint_id', right_on='id_datapoint', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={'label_categorical_id': 'class_label'}); final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select and reorder columns as needed (optional).\n",
    "final_columns = ['datapoint_id', 'datetime', 'grouping', 'filter_value', 'class_label'] + feature_df['name'].tolist()\n",
    "final_df = final_df[final_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"path_to_model\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(model_df[\"path_to_model\"][0], 'rb'))\n",
    "model_features_in = list(model.feature_names_in_); model_features_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transform(row):\n",
    "    if row[\"class_label\"] == \"low\": return 0\n",
    "    elif row[\"class_label\"] == \"low-med\": return 1\n",
    "    elif row[\"class_label\"] == \"medium\": return 2\n",
    "    elif row[\"class_label\"] == \"med-high\": return 3\n",
    "    elif row[\"class_label\"] == \"high\": return 4\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_df[final_df['grouping'] == \"train\"][model_features_in]\n",
    "X_test = final_df[final_df['grouping'] == \"test\"][model_features_in]\n",
    "y_train = final_df[final_df['grouping'] == \"train\"][\"class_label\"]\n",
    "y_train_trans = final_df[final_df['grouping'] == \"train\"].apply(label_transform, axis=1)\n",
    "y_test = final_df[final_df['grouping'] == \"test\"][\"class_label\"]\n",
    "y_test_trans = final_df[final_df['grouping'] == \"test\"].apply(label_transform, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_object = shap.Explanation(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_object.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(explanation_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: model.predict_proba(x)\n",
    "feature_names = X_train.columns.to_list()\n",
    "explainer = AnchorTabular(predict_fn, feature_names)\n",
    "explainer.fit(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = X_test.to_numpy()\n",
    "test_length = X_test_np.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(sec):\n",
    "  mins = sec // 60\n",
    "  sec = sec % 60\n",
    "  hours = mins // 60\n",
    "  mins = mins % 60\n",
    "  return \"Time Lapsed = {0}:{1}:{2}\".format(int(hours),int(mins),sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = X_test.to_numpy()\n",
    "X_test_np.shape\n",
    "start_time = time.time()\n",
    "\n",
    "anchors = []\n",
    "for i, dp in enumerate(X_test_np):\n",
    "    anchors.append(explainer.explain(dp.to_numpy(), threshold=0.95))\n",
    "    current_time = time.time()\n",
    "    time_lapsed = current_time - start_time\n",
    "    print(\"{} von {} Schritten abgeschlossen. Zeit: {}\".format(i, test_length, time_convert(time_lapsed)), end=\"\\r\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors[1][\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trustscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.classes_; classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TrustScore()\n",
    "ts.fit(X_train.to_numpy(), y_train_trans.to_numpy(), classes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ts.score(X_test, y_test_trans, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_sum  = 0\n",
    "conf_sum = 0\n",
    "for i, score in enumerate(scores[1]):\n",
    "    print(\"actual prediction: {}\".format(y_test.iloc[i]))\n",
    "    print(\"closest class: {}\".format(score))\n",
    "    abs_dist = abs(y_test_trans.iloc[i] - (score))\n",
    "    print(abs_dist)\n",
    "    dist_sum = dist_sum + abs_dist\n",
    "    conf_sum = conf_sum + scores[0][i]\n",
    "\n",
    "print(dist_sum / len(scores[1]))\n",
    "print(conf_sum / len(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare model wrapper to output numerical values instead of categorical values (i.e. 0 instead of \"low\", ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class CategoricalToNumericalClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_model, class_mapping):\n",
    "        self.base_model = base_model\n",
    "        self.class_mapping = class_mapping\n",
    "        self.classes_ = list(class_mapping.values())\n",
    "        # Reverse mapping for decoding\n",
    "        self.reverse_mapping = {v: k for k, v in class_mapping.items()}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # This model is already trained, so we don't do anything here\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict using the base model\n",
    "        predictions = self.base_model.predict(X)\n",
    "        # Map categorical predictions to numerical\n",
    "        return [self.class_mapping.get(pred, -1) for pred in predictions]  # Default to -1 for unknown classes\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Optional: Implement this if you need probability estimates\n",
    "        # and your base model supports it\n",
    "        if hasattr(self.base_model, 'predict_proba'):\n",
    "            return self.base_model.predict_proba(X)\n",
    "        else:\n",
    "            raise NotImplementedError(\"This model does not support predict_proba.\")\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        # Convert numerical predictions back to categorical\n",
    "        return [self.reverse_mapping[pred] for pred in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {'low': 0, 'low-med': 1, 'medium': 2, 'med-high': 3, 'high': 4}\n",
    "model_wrapper = CategoricalToNumericalClassifier(base_model=model, class_mapping=class_mapping)\n",
    "\n",
    "# this does nothing as the model is already trained! It is just done to sign that the model is trained\n",
    "model_wrapper.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, feature in enumerate(X_test.columns):\n",
    "    pdp = partial_dependence(model_wrapper, X_test, [index], kind=\"average\")\n",
    "    for cl_index, cl in enumerate(model_wrapper.classes_):\n",
    "        print(\n",
    "            {\n",
    "                \"feature\": feature,\n",
    "                \"class\": int(cl),\n",
    "                \"average\": pdp[\"average\"][cl_index].tolist()\n",
    "            }\n",
    "        )\n",
    "        print(\n",
    "            {\n",
    "                \"feature\": feature,\n",
    "                \"class\": int(cl),\n",
    "                \"values\": pdp[\"values\"][0].tolist()\n",
    "            }\n",
    "        )\n",
    "        # for elem_ind, elem in enumerate(pdp[\"individual\"][cl_index]):\n",
    "        #     print(\n",
    "        #         {\n",
    "        #             \"feature\": feature,\n",
    "        #             \"class\": int(cl),\n",
    "        #             \"index\": elem_ind,\n",
    "        #             \"individual\": elem.tolist()\n",
    "        #         }\n",
    "        #     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PartialDependenceDisplay.from_estimator(model_wrapper, X_train, [X_train.columns[-1]], target=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import create_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = dict()\n",
    "context[\"base\"] = Base\n",
    "context[\"session\"] = Session(bind=engine)\n",
    "\n",
    "# TODO setup correct model reference\n",
    "model = None\n",
    "feature_ids = list(feature_df[\"id\"])\n",
    "datapoint_ids = list(datapoint_df[\"id\"])\n",
    "\n",
    "for feature_id in feature_ids:\n",
    "    for i, datapoint_id in enumerate(datapoint_ids):\n",
    "        create_object(context, \"shap\", with_commit=False,\n",
    "                        model_id = model.id,\n",
    "                        feature_id = feature_id,\n",
    "                        datapoint_id = datapoint_id,\n",
    "                        # TODO: add SHAP values based on shap value data structure\n",
    "                        value = None\n",
    "                      )\n",
    "        if (i % 5000 == 0 and i != 0):\n",
    "            context[\"session\"].commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, datapoint_id in enumerate(datapoint_ids):\n",
    "    create_object(context, \"anchors\", with_commit=False,\n",
    "                    id = i,\n",
    "                    model_id = model.id,\n",
    "                    datapoint_id = datapoint_id,\n",
    "                    # TODO: add Anchor performance values based on anchor data structure\n",
    "                    precision = None,\n",
    "                    coverage = None\n",
    "                )\n",
    "    for feature_id in feature_ids:\n",
    "        create_object(context, \"anchor_rules\", with_commit=False,\n",
    "                        anchor_id = i,\n",
    "                        feature_id = feature_id,\n",
    "                        # TODO: add boundary values based on anchor data structure\n",
    "                        lower_bound = None,\n",
    "                        upper_bound = None\n",
    "                    )\n",
    "    if (i % 5000 == 0 and i != 0):\n",
    "        context[\"session\"].commit()\n",
    "# Final commit in case something was not commited yet\n",
    "context[\"session\"].commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, datapoint_id in enumerate(datapoint_ids):\n",
    "    create_object(context, \"trustscores\", with_commit=False,\n",
    "                    model_id = model.id,\n",
    "                    datapoint_id = datapoint_id,\n",
    "                    # TODO: add Trustscore values based on trustscore data structure\n",
    "                    neighbor = None,\n",
    "                    score = None\n",
    "                    )\n",
    "    if (i % 5000 == 0 and i != 0):\n",
    "        context[\"session\"].commit()\n",
    "# Final commit in case something was not commited yet\n",
    "context[\"session\"].commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, feature_id in enumerate(feature_ids):\n",
    "    for j, class_id in enumerate(classes):\n",
    "        # Calculate unique, up-counting id based on i and j.\n",
    "        unique_id = ((i+j) * (i+j+1) / 2) + j\n",
    "        create_object(context, \"partial_dependence\", with_commit=False,\n",
    "                        id = unique_id,\n",
    "                        model_id = model.id,\n",
    "                        feature_id = feature_id,\n",
    "                        label_id = class_id\n",
    "                      )\n",
    "        create_object(context, \"partial_dependence_average\", with_commit=False,\n",
    "                    partial_dependence_id = unique_id,\n",
    "                    # TODO: add PDP values based on PDP data structure\n",
    "                    feature_value = None,\n",
    "                    pd_value = None,\n",
    "                    index = None\n",
    "                )\n",
    "        \n",
    "context[\"session\"].commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
